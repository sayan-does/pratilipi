{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting implicit\n",
      "  Downloading implicit-0.7.2-cp310-cp310-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\sayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\sayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.26.2)\n",
      "Requirement already satisfied: scipy>=0.16 in c:\\users\\sayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from implicit) (1.15.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from implicit) (4.66.1)\n",
      "Requirement already satisfied: threadpoolctl in c:\\users\\sayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from implicit) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sayan\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\sayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sayan\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->implicit) (0.4.4)\n",
      "Downloading implicit-0.7.2-cp310-cp310-win_amd64.whl (748 kB)\n",
      "   ---------------------------------------- 0.0/748.6 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 262.1/748.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 748.6/748.6 kB 2.1 MB/s eta 0:00:00\n",
      "Installing collected packages: implicit\n",
      "Successfully installed implicit-0.7.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install implicit scikit-learn pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(user_interactions_path, meta_data_path):\n",
    "    interactions_df = pd.read_csv(user_interactions_path)\n",
    "    meta_df = pd.read_csv(meta_data_path)\n",
    "    \n",
    "    # Convert timestamps\n",
    "    interactions_df['updated_at'] = pd.to_datetime(interactions_df['updated_at'])\n",
    "    meta_df['updated_at'] = pd.to_datetime(meta_df['updated_at'])\n",
    "    meta_df['published_at'] = pd.to_datetime(meta_df['published_at'])\n",
    "    \n",
    "    interactions_df = interactions_df.sort_values('updated_at')\n",
    "    \n",
    "    return interactions_df, meta_df\n",
    "\n",
    "interactions_df, meta_df = load_and_preprocess_data('user_interaction.csv', 'metadata.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Interactions:\n",
      "                  user_id      pratilipi_id  read_percent  \\\n",
      "1033131  5506791954036110  1377786225804654         100.0   \n",
      "1415300  5506791980439899  1377786228150074         100.0   \n",
      "2318259  5506791979182708  1377786218415632         100.0   \n",
      "952322   5506791996330389  1377786219497547         100.0   \n",
      "2114134  5506791961370166  1377786224952303         100.0   \n",
      "\n",
      "                     updated_at  \n",
      "1033131 2022-03-18 15:14:41.827  \n",
      "1415300 2022-03-18 15:14:42.120  \n",
      "2318259 2022-03-18 15:14:42.134  \n",
      "952322  2022-03-18 15:14:42.170  \n",
      "2114134 2022-03-18 15:14:42.282  \n",
      "\n",
      "Meta Data:\n",
      "          author_id      pratilipi_id category_name  reading_time  \\\n",
      "0 -3418949279741297  1025741862639304   translation             0   \n",
      "1 -2270332351871840  1377786215601277   translation           171   \n",
      "2 -2270332352037261  1377786215601962   translation            92   \n",
      "3 -2270332352521845  1377786215640994   translation             0   \n",
      "4 -2270332349665658  1377786215931338   translation            47   \n",
      "\n",
      "           updated_at        published_at  \n",
      "0 2020-08-19 15:26:13 2016-09-30 10:37:04  \n",
      "1 2021-01-21 16:27:07 2018-06-11 13:17:48  \n",
      "2 2020-09-29 12:33:57 2018-06-12 04:19:12  \n",
      "3 2019-10-17 09:03:37 2019-09-26 14:58:53  \n",
      "4 2020-05-05 11:33:41 2018-11-25 12:28:23  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"User Interactions:\")\n",
    "print(interactions_df.head())\n",
    "print(\"\\nMeta Data:\")\n",
    "print(meta_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data structure:\n",
      "\n",
      "Columns: ['user_id', 'pratilipi_id', 'read_percent', 'updated_at']\n",
      "\n",
      "Sample of data:\n",
      "                  user_id      pratilipi_id  read_percent  \\\n",
      "1033131  5506791954036110  1377786225804654         100.0   \n",
      "1415300  5506791980439899  1377786228150074         100.0   \n",
      "2318259  5506791979182708  1377786218415632         100.0   \n",
      "952322   5506791996330389  1377786219497547         100.0   \n",
      "2114134  5506791961370166  1377786224952303         100.0   \n",
      "\n",
      "                     updated_at  \n",
      "1033131 2022-03-18 15:14:41.827  \n",
      "1415300 2022-03-18 15:14:42.120  \n",
      "2318259 2022-03-18 15:14:42.134  \n",
      "952322  2022-03-18 15:14:42.170  \n",
      "2114134 2022-03-18 15:14:42.282  \n",
      "\n",
      "Data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2500000 entries, 1033131 to 2186369\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Dtype         \n",
      "---  ------        -----         \n",
      " 0   user_id       int64         \n",
      " 1   pratilipi_id  int64         \n",
      " 2   read_percent  float64       \n",
      " 3   updated_at    datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(1), int64(2)\n",
      "memory usage: 95.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking data structure:\")\n",
    "print(\"\\nColumns:\", interactions_df.columns.tolist())\n",
    "print(\"\\nSample of data:\")\n",
    "print(interactions_df.head())\n",
    "print(\"\\nData info:\")\n",
    "print(interactions_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data...\n",
      "Creating sparse matrix...\n",
      "Matrix shape: (213331, 219088)\n",
      "Matrix density: 0.004011702435287433 %\n"
     ]
    }
   ],
   "source": [
    "def create_user_item_matrix(interactions_df):\n",
    "    # Convert IDs to categorical codes to save memory\n",
    "    users = pd.Categorical(interactions_df['user_id'])\n",
    "    items = pd.Categorical(interactions_df['pratilipi_id'])\n",
    "    \n",
    "    # Create mappings\n",
    "    user_to_idx = dict(zip(users.categories, range(len(users.categories))))\n",
    "    item_to_idx = dict(zip(items.categories, range(len(items.categories))))\n",
    "    \n",
    "    # Create sparse matrix\n",
    "    rows = interactions_df['user_id'].map(user_to_idx)\n",
    "    cols = interactions_df['pratilipi_id'].map(item_to_idx)\n",
    "    data = interactions_df['read_percent'].astype('float32')  # Convert to float32 to save memory\n",
    "    \n",
    "    sparse_matrix = csr_matrix(\n",
    "        (data, (rows, cols)),\n",
    "        shape=(len(user_to_idx), len(item_to_idx))\n",
    "    )\n",
    "    \n",
    "    return sparse_matrix, user_to_idx, item_to_idx\n",
    "\n",
    "# Split and create matrix\n",
    "print(\"Splitting data...\")\n",
    "train_data, test_data = train_test_split_by_time(interactions_df)\n",
    "\n",
    "print(\"Creating sparse matrix...\")\n",
    "sparse_matrix, user_to_idx, item_to_idx = create_user_item_matrix(train_data)\n",
    "\n",
    "print(\"Matrix shape:\", sparse_matrix.shape)\n",
    "print(\"Matrix density:\", (sparse_matrix.nnz / (sparse_matrix.shape[0] * sparse_matrix.shape[1])) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf3a3242af344f081d2bca4743f0f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_model(sparse_matrix, factors=100):\n",
    "    print(\"Training model...\")\n",
    "    model = AlternatingLeastSquares(\n",
    "        factors=factors,\n",
    "        regularization=0.1,\n",
    "        iterations=20,\n",
    "        calculate_training_loss=True,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(sparse_matrix.T)\n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "model = train_model(sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(model, sparse_matrix, user_idx, n_items=5):\n",
    "    \"\"\"\n",
    "    Get recommendations for a user with dimension alignment\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get user's interaction vector\n",
    "        user_items = sparse_matrix[user_idx]\n",
    "        \n",
    "        # Ensure we only look at items within the model's known range\n",
    "        n_items = min(n_items, model.item_factors.shape[0])\n",
    "        \n",
    "        recommendations, scores = model.recommend(\n",
    "            userid=user_idx,\n",
    "            user_items=user_items,\n",
    "            N=n_items,\n",
    "            filter_already_liked_items=True,\n",
    "            items=range(model.item_factors.shape[0])  # Explicitly specify valid item range\n",
    "        )\n",
    "        \n",
    "        return recommendations\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting recommendations for user {user_idx}\")\n",
    "        print(f\"Error details: {str(e)}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced function to analyze recommendations\n",
    "def analyze_recommendations(recommendations, meta_df, user_id):\n",
    "    print(f\"\\nRecommendations for user {user_id}:\")\n",
    "    recommended_stories = meta_df[meta_df['pratilipi_id'].isin(recommendations)]\n",
    "    \n",
    "    if len(recommended_stories) > 0:\n",
    "        # Group by story to show all categories for each\n",
    "        for story_id in recommendations:\n",
    "            story_data = recommended_stories[recommended_stories['pratilipi_id'] == story_id]\n",
    "            if len(story_data) > 0:\n",
    "                print(f\"\\nStory ID: {story_id}\")\n",
    "                print(f\"Categories: {', '.join(story_data['category_name'].unique())}\")\n",
    "                print(f\"Reading time: {story_data['reading_time'].iloc[0]} seconds\")\n",
    "    else:\n",
    "        print(\"No story details found for recommendations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing recommendations with fixed dimensions...\n",
      "\n",
      "Processing user 3257552805995172 (index: 0)\n",
      "\n",
      "Recommendations for user 3257552805995172:\n",
      "\n",
      "Story ID: 1377786224881573\n",
      "Categories: novels, life, romance\n",
      "Reading time: 683 seconds\n",
      "\n",
      "Processing user 3257621147984548 (index: 1)\n",
      "\n",
      "Recommendations for user 3257621147984548:\n",
      "\n",
      "Story ID: 1377786225349769\n",
      "Categories: relegion-and-spiritual, mythology, shortstories\n",
      "Reading time: 150 seconds\n",
      "\n",
      "Story ID: 1377786216799473\n",
      "Categories: suspense, horror\n",
      "Reading time: 182 seconds\n",
      "\n",
      "Processing user 3260275089121956 (index: 2)\n",
      "\n",
      "Recommendations for user 3260275089121956:\n",
      "\n",
      "Story ID: 1377786222974562\n",
      "Categories: crime, Indiawale, suspense\n",
      "Reading time: 415 seconds\n",
      "\n",
      "Story ID: 1377786224927001\n",
      "Categories: novels, webseries\n",
      "Reading time: 441 seconds\n",
      "\n",
      "Story ID: 1377786222916063\n",
      "Categories: family, romance\n",
      "Reading time: 406 seconds\n",
      "\n",
      "Processing user 3260433621754532 (index: 3)\n",
      "\n",
      "Recommendations for user 3260433621754532:\n",
      "\n",
      "Story ID: 1377786225234630\n",
      "Categories: romance, suspense\n",
      "Reading time: 2053 seconds\n",
      "\n",
      "Story ID: 1377786221907837\n",
      "Categories: romance\n",
      "Reading time: 1076 seconds\n",
      "\n",
      "Story ID: 1377786225663448\n",
      "Categories: life, romance, suspense\n",
      "Reading time: 330 seconds\n",
      "\n",
      "Processing user 3263710062617252 (index: 4)\n",
      "\n",
      "Recommendations for user 3263710062617252:\n",
      "\n",
      "Story ID: 1377786221051337\n",
      "Categories: action-and-adventure\n",
      "Reading time: 402 seconds\n",
      "\n",
      "Story ID: 1377786228252246\n",
      "Categories: crime, crime-lekhan, webseries\n",
      "Reading time: 890 seconds\n",
      "\n",
      "Story ID: 1377786226095999\n",
      "Categories: entertainment\n",
      "Reading time: 609 seconds\n",
      "\n",
      "Story ID: 1377786228199846\n",
      "Categories: romance, politics, social\n",
      "Reading time: 329 seconds\n",
      "\n",
      "Story ID: 1377786227286912\n",
      "Categories: crime, detective, suspense\n",
      "Reading time: 541 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting recommendations with fixed dimensions...\")\n",
    "\n",
    "for i in range(5):  # Test first 5 users\n",
    "    try:\n",
    "        user_id = list(user_to_idx.keys())[i]\n",
    "        user_idx = user_to_idx[user_id]\n",
    "        \n",
    "        print(f\"\\nProcessing user {user_id} (index: {user_idx})\")\n",
    "        recommendations = get_recommendations(model, sparse_matrix, user_idx)\n",
    "        \n",
    "        if len(recommendations) > 0:\n",
    "            original_ids = convert_to_original_ids(recommendations, item_to_idx)\n",
    "            analyze_recommendations(original_ids, meta_df, user_id)\n",
    "        else:\n",
    "            print(f\"No recommendations generated for user {user_id}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing user at index {i}\")\n",
    "        print(f\"Error details: {str(e)}\")\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
